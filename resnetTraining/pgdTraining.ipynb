{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyush/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "[ Train epoch: 0 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "from resnet import *\n",
    "\n",
    "learning_rate = 0.01\n",
    "epsilon = 8/255\n",
    "k = 20\n",
    "alpha = 3/255\n",
    "file_name = 'pgd_adversarial_training'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "class LinfPGDAttack(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def perturb(self, x_natural, y):\n",
    "        x = x_natural.detach()\n",
    "        x = x + torch.zeros_like(x).uniform_(-epsilon, epsilon)\n",
    "        for i in range(k):\n",
    "            x.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits = self.model(x)\n",
    "                loss = F.cross_entropy(logits, y)\n",
    "            grad = torch.autograd.grad(loss, [x])[0]\n",
    "            x = x.detach() + alpha * torch.sign(grad.detach())\n",
    "            x = torch.min(torch.max(x, x_natural - epsilon), x_natural + epsilon)\n",
    "            x = torch.clamp(x, 0, 1)\n",
    "        return x\n",
    "\n",
    "def attack(x, y, model, adversary):\n",
    "    model_copied = copy.deepcopy(model)\n",
    "    model_copied.eval()\n",
    "    adversary.model = model_copied\n",
    "    adv = adversary.perturb(x, y)\n",
    "    return adv\n",
    "\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "adversary = LinfPGDAttack(net)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_adv_list = []\n",
    "test_loss_benign_list = []\n",
    "accuracy_adv_list = []\n",
    "accuracy_benign_list = []\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        adv = adversary.perturb(inputs, targets)\n",
    "        adv_outputs = net(adv)\n",
    "        loss = criterion(adv_outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = adv_outputs.max(1)\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current adversarial train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current adversarial train loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal adversarial train accuarcy:', 100. * correct / total)\n",
    "    print('Total adversarial train loss:', train_loss)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    benign_loss = 0\n",
    "    adv_loss = 0\n",
    "    benign_correct = 0\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            total += targets.size(0)\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            benign_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            benign_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('\\nCurrent batch:', str(batch_idx))\n",
    "                print('Current benign test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "                print('Current benign test loss:', loss.item())\n",
    "\n",
    "            adv = adversary.perturb(inputs, targets)\n",
    "            adv_outputs = net(adv)\n",
    "            loss = criterion(adv_outputs, targets)\n",
    "            adv_loss += loss.item()\n",
    "\n",
    "            _, predicted = adv_outputs.max(1)\n",
    "            adv_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Current adversarial test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "                print('Current adversarial test loss:', loss.item())\n",
    "\n",
    "    print('\\nTotal benign test accuarcy:', 100. * benign_correct / total)\n",
    "    print('Total adversarial test Accuarcy:', 100. * adv_correct / total)\n",
    "    print('Total benign test loss:', benign_loss)\n",
    "    print('Total adversarial test loss:', adv_loss)\n",
    "    test_loss_adv_list.append(adv_loss)\n",
    "    test_loss_benign_list.append(benign_loss)\n",
    "    accuracy_adv_list.append(100. * adv_correct / total)\n",
    "    accuracy_benign_list.append(100. * benign_correct / total)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "for epoch in range(0, 200):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    \n",
    "# Save the model parameters\n",
    "torch.save(net.state_dict(), 'resnet18_githubPGD20_epoch200_better.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs=200\n",
    "plt.plot(np.arange(1,epochs+1),train_loss_list, label='train losses')\n",
    "plt.plot(np.arange(1,epochs+1), test_loss_adv_list, label='test losses in adversarial examples')\n",
    "plt.plot(np.arange(1,epochs+1), test_loss_benign_list, label='test losses in benign examples')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,epochs+1), accuracy_adv_list, label='accuracy in adversarial examples')\n",
    "plt.plot(np.arange(1,epochs+1), accuracy_benign_list, label='accuracy in benign examples')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
