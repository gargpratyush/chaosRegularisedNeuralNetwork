{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m delta_x_adv \u001b[38;5;241m=\u001b[39m epsilon \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(torch\u001b[38;5;241m.\u001b[39mrandn_like(images))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Calculate the susceptibility ratio for the batch\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m susceptibility \u001b[38;5;241m=\u001b[39m \u001b[43msusceptibility_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_x_adv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSusceptibility Ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msusceptibility\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m, in \u001b[0;36msusceptibility_ratio\u001b[0;34m(net, x, delta_x_adv)\u001b[0m\n\u001b[1;32m     50\u001b[0m denom \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(delta_x_adv, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     52\u001b[0m susceptibility \u001b[38;5;241m=\u001b[39m num\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m denom\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msusceptibility\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load ResNet18 model\n",
    "net = resnet18(pretrained=True)\n",
    "net = net.to(device)\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, delta_x_adv):\n",
    "    x = x.to(device)\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Calculate h(θ; x_i)\n",
    "    output_x = net(x)\n",
    "    \n",
    "    # Calculate h(θ; x_i + δx_adv)\n",
    "    output_x_adv = net(x + delta_x_adv)\n",
    "    \n",
    "    # Calculate the susceptibility ratio\n",
    "    num = torch.norm(output_x - output_x_adv, p=2)\n",
    "    denom = torch.norm(delta_x_adv, p=2)\n",
    "    \n",
    "    susceptibility = torch.exp(num / denom)\n",
    "    return susceptibility.item()\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibility = susceptibility_ratio(net, images, delta_x_adv)\n",
    "print(f'Susceptibility Ratio: {susceptibility}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Loading basic ResNet model..\n",
      "==> Loading FGSM-trained model..\n",
      "==> Loading PGD-trained model..\n",
      "==> Loading ChaosLoss Minimization model..\n",
      "Susceptibility Ratio of Basic Model: 1.9929317235946655\n",
      "Susceptibility Ratio of Adversarially Trained (FGSM) Model: 1.0672930479049683\n",
      "Susceptibility Ratio of Adversarially Trained (PGD) Model: 1.1436617374420166\n",
      "Susceptibility Ratio of Chaos-loss trained Model: 1.069597601890564\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "from resnet import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load ResNet18 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with FGSM adversarial training\n",
    "print('==> Loading FGSM-trained model..')\n",
    "net_fgsm = ResNet18()\n",
    "net_fgsm = net_fgsm.to(device)\n",
    "if device == 'cuda':\n",
    "    net_fgsm = torch.nn.DataParallel(net_fgsm)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_fgsmTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_fgsm.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with PGD adversarial training\n",
    "print('==> Loading PGD-trained model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_pgdTraining_iter20.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with Chaos Loss minimization training\n",
    "print('==> Loading ChaosLoss Minimization model..')\n",
    "net_chaosLoss = ResNet18()\n",
    "net_chaosLoss = net_chaosLoss.to(device)\n",
    "if device == 'cuda':\n",
    "    net_chaosLoss = torch.nn.DataParallel(net_chaosLoss)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_chaos_regularized_pgd_torchattacks_lambdaChaos0.8_epoch100_lr0.01.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('resnet18.'):\n",
    "        name = k[9:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_chaosLoss.load_state_dict(new_state_dict)\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, delta_x_adv):\n",
    "    x = x.to(device)\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Calculate h(θ; x_i)\n",
    "    output_x = net(x)\n",
    "    \n",
    "    # Calculate h(θ; x_i + δx_adv)\n",
    "    output_x_adv = net(x + delta_x_adv)\n",
    "    \n",
    "    # Calculate the susceptibility ratio\n",
    "    num = torch.norm(output_x - output_x_adv, p=2)\n",
    "    denom = torch.norm(delta_x_adv, p=2)\n",
    "    \n",
    "    susceptibility = torch.exp(num / denom)\n",
    "    return susceptibility.item()\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "delta_x_adv = epsilon * torch.sign(torch.randn_like(images)) #FGSM Attack\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibility_basic_model = susceptibility_ratio(net, images, delta_x_adv)\n",
    "susceptibility_fgsm_model = susceptibility_ratio(net_fgsm, images, delta_x_adv)\n",
    "susceptibility_pgd_model = susceptibility_ratio(net_pgd, images, delta_x_adv)\n",
    "susceptibility_chaosLoss_model = susceptibility_ratio(net_chaosLoss, images, delta_x_adv)\n",
    "print(f'Susceptibility Ratio of Basic Model: {susceptibility_basic_model}')\n",
    "print(f'Susceptibility Ratio of Adversarially Trained (FGSM) Model: {susceptibility_fgsm_model}')\n",
    "print(f'Susceptibility Ratio of Adversarially Trained (PGD) Model: {susceptibility_pgd_model}')\n",
    "print(f'Susceptibility Ratio of Chaos-loss trained Model: {susceptibility_chaosLoss_model}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.shortcut.0.weight\", \"layer4.0.shortcut.1.weight\", \"layer4.0.shortcut.1.bias\", \"layer4.0.shortcut.1.running_mean\", \"layer4.0.shortcut.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"linear.weight\", \"linear.bias\". \n\tUnexpected key(s) in state_dict: \"net\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m         name \u001b[38;5;241m=\u001b[39m k\n\u001b[1;32m     58\u001b[0m     new_state_dict[name] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m---> 60\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#Load ResNet18 model with PGD adversarial training\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==> Loading PGD-trained model..\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1051\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   1047\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1048\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1051\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1052\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tMissing key(s) in state_dict: \"conv1.weight\", \"bn1.weight\", \"bn1.bias\", \"bn1.running_mean\", \"bn1.running_var\", \"layer1.0.conv1.weight\", \"layer1.0.bn1.weight\", \"layer1.0.bn1.bias\", \"layer1.0.bn1.running_mean\", \"layer1.0.bn1.running_var\", \"layer1.0.conv2.weight\", \"layer1.0.bn2.weight\", \"layer1.0.bn2.bias\", \"layer1.0.bn2.running_mean\", \"layer1.0.bn2.running_var\", \"layer1.1.conv1.weight\", \"layer1.1.bn1.weight\", \"layer1.1.bn1.bias\", \"layer1.1.bn1.running_mean\", \"layer1.1.bn1.running_var\", \"layer1.1.conv2.weight\", \"layer1.1.bn2.weight\", \"layer1.1.bn2.bias\", \"layer1.1.bn2.running_mean\", \"layer1.1.bn2.running_var\", \"layer2.0.conv1.weight\", \"layer2.0.bn1.weight\", \"layer2.0.bn1.bias\", \"layer2.0.bn1.running_mean\", \"layer2.0.bn1.running_var\", \"layer2.0.conv2.weight\", \"layer2.0.bn2.weight\", \"layer2.0.bn2.bias\", \"layer2.0.bn2.running_mean\", \"layer2.0.bn2.running_var\", \"layer2.0.shortcut.0.weight\", \"layer2.0.shortcut.1.weight\", \"layer2.0.shortcut.1.bias\", \"layer2.0.shortcut.1.running_mean\", \"layer2.0.shortcut.1.running_var\", \"layer2.1.conv1.weight\", \"layer2.1.bn1.weight\", \"layer2.1.bn1.bias\", \"layer2.1.bn1.running_mean\", \"layer2.1.bn1.running_var\", \"layer2.1.conv2.weight\", \"layer2.1.bn2.weight\", \"layer2.1.bn2.bias\", \"layer2.1.bn2.running_mean\", \"layer2.1.bn2.running_var\", \"layer3.0.conv1.weight\", \"layer3.0.bn1.weight\", \"layer3.0.bn1.bias\", \"layer3.0.bn1.running_mean\", \"layer3.0.bn1.running_var\", \"layer3.0.conv2.weight\", \"layer3.0.bn2.weight\", \"layer3.0.bn2.bias\", \"layer3.0.bn2.running_mean\", \"layer3.0.bn2.running_var\", \"layer3.0.shortcut.0.weight\", \"layer3.0.shortcut.1.weight\", \"layer3.0.shortcut.1.bias\", \"layer3.0.shortcut.1.running_mean\", \"layer3.0.shortcut.1.running_var\", \"layer3.1.conv1.weight\", \"layer3.1.bn1.weight\", \"layer3.1.bn1.bias\", \"layer3.1.bn1.running_mean\", \"layer3.1.bn1.running_var\", \"layer3.1.conv2.weight\", \"layer3.1.bn2.weight\", \"layer3.1.bn2.bias\", \"layer3.1.bn2.running_mean\", \"layer3.1.bn2.running_var\", \"layer4.0.conv1.weight\", \"layer4.0.bn1.weight\", \"layer4.0.bn1.bias\", \"layer4.0.bn1.running_mean\", \"layer4.0.bn1.running_var\", \"layer4.0.conv2.weight\", \"layer4.0.bn2.weight\", \"layer4.0.bn2.bias\", \"layer4.0.bn2.running_mean\", \"layer4.0.bn2.running_var\", \"layer4.0.shortcut.0.weight\", \"layer4.0.shortcut.1.weight\", \"layer4.0.shortcut.1.bias\", \"layer4.0.shortcut.1.running_mean\", \"layer4.0.shortcut.1.running_var\", \"layer4.1.conv1.weight\", \"layer4.1.bn1.weight\", \"layer4.1.bn1.bias\", \"layer4.1.bn1.running_mean\", \"layer4.1.bn1.running_var\", \"layer4.1.conv2.weight\", \"layer4.1.bn2.weight\", \"layer4.1.bn2.bias\", \"layer4.1.bn2.running_mean\", \"layer4.1.bn2.running_var\", \"linear.weight\", \"linear.bias\". \n\tUnexpected key(s) in state_dict: \"net\". "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import *\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "from models import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load ResNet18 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/models/basic_training\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with PGD adversarial training\n",
    "print('==> Loading PGD-trained model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/models/pgd_adversarial_training\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd.load_state_dict(new_state_dict)\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, delta_x_adv):\n",
    "    x = x.to(device)\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Calculate h(θ; x_i)\n",
    "    output_x = net(x)\n",
    "    \n",
    "    # Calculate h(θ; x_i + δx_adv)\n",
    "    output_x_adv = net(x + delta_x_adv)\n",
    "    \n",
    "    # Calculate the susceptibility ratio\n",
    "    num = torch.norm(output_x - output_x_adv, p=2)\n",
    "    denom = torch.norm(delta_x_adv, p=2)\n",
    "    \n",
    "    susceptibility = torch.exp(num / denom)\n",
    "    return susceptibility.item()\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibility_basic_model = susceptibility_ratio(net, images, delta_x_adv)\n",
    "susceptibility_pgd_model = susceptibility_ratio(net_chaosLoss, images, delta_x_adv)\n",
    "\n",
    "print(f'Susceptibility Ratio of Basic Model: {susceptibility_basic_model}')\n",
    "print(f'Susceptibility Ratio of Adversarially Trained (PGD) Model: {susceptibility_pgd_model}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Susceptibility Ratio for Layer relu: 2.312288284301758\n",
      "Susceptibility Ratio for Layer layer1: 5.430505275726318\n",
      "Susceptibility Ratio for Layer layer2: 2.6668903827667236\n",
      "Susceptibility Ratio for Layer layer3: 1.7329432964324951\n",
      "Susceptibility Ratio for Layer layer4: 2.4794650077819824\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load ResNet18 model\n",
    "net = resnet18(pretrained=True)\n",
    "net = net.to(device)\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define a function to register hooks and capture intermediate outputs\n",
    "def register_hooks(model, layers):\n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output\n",
    "        return hook\n",
    "    \n",
    "    for name, layer in model.named_modules():\n",
    "        if name in layers:\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "    \n",
    "    return activations\n",
    "\n",
    "# Define the layers to capture\n",
    "layers_to_capture = ['relu', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "activations = register_hooks(net, layers_to_capture)\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, delta_x_adv, activations, layers_to_capture):\n",
    "    x = x.to(device)\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Clear previous activations\n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for original input\n",
    "    _ = net(x)\n",
    "    output_x_layers = {layer: activations[layer] for layer in layers_to_capture}\n",
    "    \n",
    "    # Clear previous activations\n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for perturbed input\n",
    "    _ = net(x + delta_x_adv)\n",
    "    output_x_adv_layers = {layer: activations[layer] for layer in layers_to_capture}\n",
    "    \n",
    "    susceptibilities = {}\n",
    "    for layer in layers_to_capture:\n",
    "        output_x = output_x_layers[layer]\n",
    "        output_x_adv = output_x_adv_layers[layer]\n",
    "        \n",
    "        # Calculate the susceptibility ratio for each layer\n",
    "        num = torch.norm(output_x - output_x_adv, p=2)\n",
    "        denom = torch.norm(delta_x_adv, p=2)\n",
    "        susceptibility = torch.exp(num / denom)\n",
    "        susceptibilities[layer] = susceptibility.item()\n",
    "    \n",
    "    return susceptibilities\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibilities = susceptibility_ratio(net, images, delta_x_adv, activations, layers_to_capture)\n",
    "for layer, sus in susceptibilities.items():\n",
    "    print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Loading basic ResNet model..\n",
      "==> Loading FGSM-trained model..\n",
      "==> Loading PGD-trained model..\n",
      "Registered hook for conv1\n",
      "Registered hook for bn1\n",
      "Registered hook for layer1.0.conv1\n",
      "Registered hook for layer1.0.bn1\n",
      "Registered hook for layer1.0.conv2\n",
      "Registered hook for layer1.0.bn2\n",
      "Registered hook for layer1.1.conv1\n",
      "Registered hook for layer1.1.bn1\n",
      "Registered hook for layer1.1.conv2\n",
      "Registered hook for layer1.1.bn2\n",
      "Registered hook for layer2.0.conv1\n",
      "Registered hook for layer2.0.bn1\n",
      "Registered hook for layer2.0.conv2\n",
      "Registered hook for layer2.0.bn2\n",
      "Registered hook for layer2.0.shortcut.0\n",
      "Registered hook for layer2.0.shortcut.1\n",
      "Registered hook for layer2.1.conv1\n",
      "Registered hook for layer2.1.bn1\n",
      "Registered hook for layer2.1.conv2\n",
      "Registered hook for layer2.1.bn2\n",
      "Registered hook for layer3.0.conv1\n",
      "Registered hook for layer3.0.bn1\n",
      "Registered hook for layer3.0.conv2\n",
      "Registered hook for layer3.0.bn2\n",
      "Registered hook for layer3.0.shortcut.0\n",
      "Registered hook for layer3.0.shortcut.1\n",
      "Registered hook for layer3.1.conv1\n",
      "Registered hook for layer3.1.bn1\n",
      "Registered hook for layer3.1.conv2\n",
      "Registered hook for layer3.1.bn2\n",
      "Registered hook for layer4.0.conv1\n",
      "Registered hook for layer4.0.bn1\n",
      "Registered hook for layer4.0.conv2\n",
      "Registered hook for layer4.0.bn2\n",
      "Registered hook for layer4.0.shortcut.0\n",
      "Registered hook for layer4.0.shortcut.1\n",
      "Registered hook for layer4.1.conv1\n",
      "Registered hook for layer4.1.bn1\n",
      "Registered hook for layer4.1.conv2\n",
      "Registered hook for layer4.1.bn2\n",
      "Registered hook for linear\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'layer' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 171\u001b[0m\n\u001b[1;32m    168\u001b[0m delta_x_adv \u001b[38;5;241m=\u001b[39m epsilon \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(torch\u001b[38;5;241m.\u001b[39mrandn_like(images))\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# Calculate the susceptibility ratio for the batch\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m susceptibilities_basic \u001b[38;5;241m=\u001b[39m \u001b[43msusceptibility_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_x_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers_to_capture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# susceptibilities_fgsm = susceptibility_ratio(net_fgsm, images, delta_x_adv, activations, layers_to_capture)\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# susceptibilities_pgd = susceptibility_ratio(net_pgd, images, delta_x_adv, activations, layers_to_capture)\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer, sus \u001b[38;5;129;01min\u001b[39;00m susceptibilities_basic\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[31], line 140\u001b[0m, in \u001b[0;36msusceptibility_ratio\u001b[0;34m(net, x, delta_x_adv, activations, layers_to_capture)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Forward pass for original input\u001b[39;00m\n\u001b[1;32m    139\u001b[0m _ \u001b[38;5;241m=\u001b[39m net(x)\n\u001b[0;32m--> 140\u001b[0m output_x_layers \u001b[38;5;241m=\u001b[39m {\u001b[43mlayer\u001b[49m: activations[layer]}\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Clear previous activations\u001b[39;00m\n\u001b[1;32m    143\u001b[0m activations\u001b[38;5;241m.\u001b[39mclear()\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'layer' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from resnet import *\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load ResNet18 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with FGSM adversarial training\n",
    "print('==> Loading FGSM-trained model..')\n",
    "net_fgsm = ResNet18()\n",
    "net_fgsm = net_fgsm.to(device)\n",
    "if device == 'cuda':\n",
    "    net_fgsm = torch.nn.DataParallel(net_fgsm)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_fgsmTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_fgsm.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with PGD adversarial training\n",
    "print('==> Loading PGD-trained model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_pgdTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd.load_state_dict(new_state_dict)\n",
    "\n",
    "# Define a function to register hooks and capture intermediate outputs\n",
    "def register_hooks(model, layers):\n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output\n",
    "        return hook\n",
    "    \n",
    "    for name, layer in model.named_modules():\n",
    "        if name in layers:\n",
    "            layer.register_forward_hook(get_activation(name))\n",
    "    \n",
    "    return activations\n",
    "\n",
    "# Define the layers to capture\n",
    "layers_to_capture = [\n",
    "    'conv1', 'bn1',\n",
    "    'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.conv2', 'layer1.0.bn2',\n",
    "    'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.conv2', 'layer1.1.bn2',\n",
    "    'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1',\n",
    "    'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.conv2', 'layer2.1.bn2',\n",
    "    'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1',\n",
    "    'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.conv2', 'layer3.1.bn2',\n",
    "    'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1',\n",
    "    'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.conv2', 'layer4.1.bn2',\n",
    "    'linear'\n",
    "]\n",
    "activations = register_hooks(net, layers_to_capture)\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, delta_x_adv, activations, layers_to_capture):\n",
    "    x = x.to(device)\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Clear previous activations\n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for original input\n",
    "    _ = net(x)\n",
    "    output_x_layers = {layer: activations[layer] for layer in layers_to_capture}\n",
    "    \n",
    "    # Clear previous activations\n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for perturbed input\n",
    "    _ = net(x + delta_x_adv)\n",
    "    output_x_adv_layers = {layer: activations[layer] for layer in layers_to_capture}\n",
    "    \n",
    "    susceptibilities = {}\n",
    "    for layer in layers_to_capture:\n",
    "        output_x = output_x_layers[layer]\n",
    "        output_x_adv = output_x_adv_layers[layer]\n",
    "        \n",
    "        # Calculate the susceptibility ratio for each layer\n",
    "        num = torch.norm(output_x - output_x_adv, p=2)\n",
    "        denom = torch.norm(delta_x_adv, p=2)\n",
    "        susceptibility = torch.exp(num / denom)\n",
    "        susceptibilities[layer] = susceptibility.item()\n",
    "    \n",
    "    return susceptibilities\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibilities_basic = susceptibility_ratio(net, images, delta_x_adv, activations, layers_to_capture)\n",
    "# susceptibilities_fgsm = susceptibility_ratio(net_fgsm, images, delta_x_adv, activations, layers_to_capture)\n",
    "susceptibilities_pgd = susceptibility_ratio(net_pgd, images, delta_x_adv, activations, layers_to_capture)\n",
    "\n",
    "for layer, sus in susceptibilities_basic.items():\n",
    "    print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n",
    "    \n",
    "print(f'\\n\\n')\n",
    "    \n",
    "# for layer, sus in susceptibilities_fgsm.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n",
    "\n",
    "# print(f'\\n\\n')\n",
    "\n",
    "for layer, sus in susceptibilities_pgd.items():\n",
    "    print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Loading basic ResNet model..\n",
      "==> Loading FGSM-trained model..\n",
      "==> Loading PGD-trained model..\n",
      "==> Loading ChaosLoss Minimization model..\n",
      "tensor(26.6267, device='cuda:0')\n",
      "tensor(26.6473, device='cuda:0')\n",
      "tensor(26.6412, device='cuda:0')\n",
      "Susceptibility Ratio Comparison when the perbutation is generated by iterative attacks (new values):\n",
      "Layer                     Basic Model     PGD Model       ChaosMin Model (λ=0.8) \n",
      "conv1                     2.023021        1.935358        87.573517      \n",
      "bn1                       1.447865        1.477958        11.581894      \n",
      "layer1.0.conv1            1.553315        1.379422        349.700378     \n",
      "layer1.0.bn1              1.892387        1.701671        5.808309       \n",
      "layer1.0.conv2            2.030166        1.514715        171.200638     \n",
      "layer1.0.bn2              3.907794        2.823645        5.741345       \n",
      "layer1.1.conv1            5.461409        2.952646        303.844269     \n",
      "layer1.1.bn1              4.038547        2.479268        7.156416       \n",
      "layer1.1.conv2            2.733451        1.614666        188.873077     \n",
      "layer1.1.bn2              6.282225        4.107156        7.022237       \n",
      "layer2.0.conv1            3.922687        2.505332        345.188049     \n",
      "layer2.0.bn1              3.404753        2.316307        5.208356       \n",
      "layer2.0.conv2            2.475127        1.923732        370.723053     \n",
      "layer2.0.bn2              5.449954        4.037376        9.312221       \n",
      "layer2.0.shortcut.0       1.839792        1.195645        77.173767      \n",
      "layer2.0.shortcut.1       3.202099        2.053041        4.277014       \n",
      "layer2.1.conv1            3.959308        2.941248        743.690002     \n",
      "layer2.1.bn1              3.728568        2.769268        5.152027       \n",
      "layer2.1.conv2            2.393958        1.697809        231.938217     \n",
      "layer2.1.bn2              6.163306        4.678990        9.549819       \n",
      "layer3.0.conv1            3.328393        2.490993        655.558716     \n",
      "layer3.0.bn1              2.878555        2.102924        4.824707       \n",
      "layer3.0.conv2            1.850365        1.367533        408.969421     \n",
      "layer3.0.bn2              4.257143        3.179548        8.051799       \n",
      "layer3.0.shortcut.0       1.549499        1.307967        149.602356     \n",
      "layer3.0.shortcut.1       2.571877        1.966664        2.420290       \n",
      "layer3.1.conv1            2.548884        1.964593        653.539246     \n",
      "layer3.1.bn1              2.832130        2.237654        4.302968       \n",
      "layer3.1.conv2            1.434424        1.226783        181.471542     \n",
      "layer3.1.bn2              4.522781        3.819097        8.337506       \n",
      "layer4.0.conv1            2.101267        1.697328        571.673462     \n",
      "layer4.0.bn1              2.352881        1.974069        4.314069       \n",
      "layer4.0.conv2            1.356918        1.099870        360.827454     \n",
      "layer4.0.bn2              3.857896        2.979769        4.881602       \n",
      "layer4.0.shortcut.0       0.973627        0.807426        136.044495     \n",
      "layer4.0.shortcut.1       2.259172        1.785914        1.138752       \n",
      "layer4.1.conv1            2.333429        1.610416        202.135818     \n",
      "layer4.1.bn1              2.677299        2.066393        5.276887       \n",
      "layer4.1.conv2            1.706067        1.039678        348.974060     \n",
      "layer4.1.bn2              5.252544        3.361185        4.800194       \n",
      "linear                    1.278552        0.708492        0.330763       \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from resnet import *\n",
    "import torchattacks\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "layers_to_capture = [\n",
    "    'conv1', 'bn1',\n",
    "    'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.conv2', 'layer1.0.bn2',\n",
    "    'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.conv2', 'layer1.1.bn2',\n",
    "    'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1',\n",
    "    'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.conv2', 'layer2.1.bn2',\n",
    "    'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1',\n",
    "    'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.conv2', 'layer3.1.bn2',\n",
    "    'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1',\n",
    "    'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.conv2', 'layer4.1.bn2',\n",
    "    'linear'\n",
    "]\n",
    "\n",
    "# Load ResNet18 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with FGSM adversarial training\n",
    "print('==> Loading FGSM-trained model..')\n",
    "net_fgsm = ResNet18()\n",
    "net_fgsm = net_fgsm.to(device)\n",
    "if device == 'cuda':\n",
    "    net_fgsm = torch.nn.DataParallel(net_fgsm)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_fgsmTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_fgsm.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with PGD adversarial training\n",
    "print('==> Loading PGD-trained model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_pgdTraining_iter20.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with Chaos Loss minimization training\n",
    "print('==> Loading ChaosLoss Minimization model..')\n",
    "net_chaosLoss = ResNet18()\n",
    "net_chaosLoss = net_chaosLoss.to(device)\n",
    "if device == 'cuda':\n",
    "    net_chaosLoss = torch.nn.DataParallel(net_chaosLoss)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_chaos_regularized_pgd_torchattacks_lambdaChaos0.8_epoch100_lr0.01.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('resnet18.'):\n",
    "        name = k[9:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_chaosLoss.load_state_dict(new_state_dict)\n",
    "\n",
    "# Define a function to register hooks and capture intermediate outputs\n",
    "def register_hooks(model):\n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output\n",
    "        return hook\n",
    "    \n",
    "    for name, layer in model.named_modules():\n",
    "        layer.register_forward_hook(get_activation(name))\n",
    "    \n",
    "    return activations\n",
    "\n",
    "# Register hooks for all layers\n",
    "activations_basic = register_hooks(net)\n",
    "activations_fgsm = register_hooks(net_fgsm)\n",
    "activations_pgd = register_hooks(net_pgd)\n",
    "activations_chaosLoss = register_hooks(net_chaosLoss)\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, labels, activations):\n",
    "    \n",
    "    x = x.to(device)\n",
    "    pgd = torchattacks.PGD(net, eps=0.03, alpha=0.01, steps=10)\n",
    "    delta_x_adv = pgd(x, labels) - x\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    # print(torch.norm(delta_x_adv, p=2))\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Clear previous activations\n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for original input\n",
    "    _ = net(x)\n",
    "    output_x_layers = activations.copy()\n",
    "    \n",
    "    # Clear previous activations\n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for perturbed input\n",
    "    _ = net(x + delta_x_adv)\n",
    "    output_x_adv_layers = activations.copy()\n",
    "    \n",
    "    susceptibilities = {}\n",
    "    for layer in output_x_layers.keys():\n",
    "        output_x = output_x_layers[layer]\n",
    "        output_x_adv = output_x_adv_layers[layer]\n",
    "        \n",
    "        # Calculate the susceptibility ratio for each layer\n",
    "        num = torch.norm(output_x - output_x_adv, p=2)\n",
    "        denom = torch.norm(delta_x_adv, p=2)\n",
    "        susceptibility = num / denom\n",
    "        # print(num.item(), denom.item(), susceptibility.item())\n",
    "        susceptibilities[layer] = susceptibility.item()\n",
    "    \n",
    "    return susceptibilities\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "# epsilon = 0.01\n",
    "# delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibilities_basic = susceptibility_ratio(net, images, labels, activations_basic)\n",
    "# susceptibilities_fgsm = susceptibility_ratio(net_fgsm, images, labels, activations_fgsm)\n",
    "susceptibilities_pgd = susceptibility_ratio(net_pgd, images, labels, activations_pgd)\n",
    "susceptibilities_chaosLoss = susceptibility_ratio(net_chaosLoss, images, labels, activations_chaosLoss)\n",
    "# Print the susceptibility ratios in a table format\n",
    "print(\"Susceptibility Ratio Comparison when the perbutation is generated by iterative attacks:\")\n",
    "print(\"{:<25} {:<15} {:<15} {:<15} \".format('Layer', 'Basic Model', 'PGD Model', 'ChaosMin Model (λ=0.8)'))\n",
    "for layer in layers_to_capture:\n",
    "    sus_basic = susceptibilities_basic[layer]\n",
    "    # sus_fgsm = susceptibilities_fgsm[layer]\n",
    "    sus_pgd = susceptibilities_pgd[layer]\n",
    "    sus_chaos = susceptibilities_chaosLoss[layer]\n",
    "    print(\"{:<25} {:<15.6f} {:<15.6f} {:<15.6f}\".format(layer, sus_basic, sus_pgd, sus_chaos))\n",
    "\n",
    "\n",
    "# for layer, sus in susceptibilities_basic.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n",
    "    \n",
    "# print(f'\\n\\n')\n",
    "    \n",
    "# for layer, sus in susceptibilities_fgsm.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n",
    "\n",
    "# print(f'\\n\\n')\n",
    "\n",
    "# for layer, sus in susceptibilities_pgd.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Loading PGD-7-trained model..\n",
      "==> Loading PGD-20-trained model..\n",
      "Susceptibility Ratio Comparison when the perbutation is generated by iterative attacks:\n",
      "Layer                     PGD-7 Model     PGD-20 Model   \n",
      "conv1                     4.984600        5.071968       \n",
      "bn1                       3.353668        3.333042       \n",
      "layer1.0.conv1            2.675270        2.601351       \n",
      "layer1.0.bn1              3.208047        3.204614       \n",
      "layer1.0.conv2            3.206050        2.983945       \n",
      "layer1.0.bn2              8.270608        7.808430       \n",
      "layer1.1.conv1            11.650421       8.006520       \n",
      "layer1.1.bn1              8.050145        5.739753       \n",
      "layer1.1.conv2            3.923095        3.252265       \n",
      "layer1.1.bn2              29.485292       19.955465      \n",
      "layer2.0.conv1            7.155480        6.200864       \n",
      "layer2.0.bn1              5.906315        5.351881       \n",
      "layer2.0.conv2            4.181568        3.890254       \n",
      "layer2.0.bn2              18.256941       17.846834      \n",
      "layer2.0.shortcut.0       2.417415        2.372538       \n",
      "layer2.0.shortcut.1       4.622621        4.401792       \n",
      "layer2.1.conv1            7.380004        7.695097       \n",
      "layer2.1.bn1              6.751835        6.810159       \n",
      "layer2.1.conv2            3.392701        3.118412       \n",
      "layer2.1.bn2              25.873806       24.346115      \n",
      "layer3.0.conv1            5.358419        5.440173       \n",
      "layer3.0.bn1              4.227194        4.172068       \n",
      "layer3.0.conv2            2.458549        2.429979       \n",
      "layer3.0.bn2              8.261233        8.284415       \n",
      "layer3.0.shortcut.0       2.298398        2.358935       \n",
      "layer3.0.shortcut.1       3.718147        3.645377       \n",
      "layer3.1.conv1            3.295293        3.491785       \n",
      "layer3.1.bn1              3.759360        4.147346       \n",
      "layer3.1.conv2            1.972032        2.196576       \n",
      "layer3.1.bn2              9.188201        11.837314      \n",
      "layer4.0.conv1            2.622193        2.894917       \n",
      "layer4.0.bn1              3.023900        3.455829       \n",
      "layer4.0.conv2            1.774230        1.836821       \n",
      "layer4.0.bn2              5.168413        5.940983       \n",
      "layer4.0.shortcut.0       1.610989        1.690055       \n",
      "layer4.0.shortcut.1       2.928785        3.204674       \n",
      "layer4.1.conv1            2.369940        2.445917       \n",
      "layer4.1.bn1              2.837896        3.141615       \n",
      "layer4.1.conv2            1.631238        1.719397       \n",
      "layer4.1.bn2              5.474479        6.380988       \n",
      "linear                    1.374941        1.410207       \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from resnet import *\n",
    "import torchattacks\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "layers_to_capture = [\n",
    "    'conv1', 'bn1',\n",
    "    'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.conv2', 'layer1.0.bn2',\n",
    "    'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.conv2', 'layer1.1.bn2',\n",
    "    'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.shortcut.0', 'layer2.0.shortcut.1',\n",
    "    'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.conv2', 'layer2.1.bn2',\n",
    "    'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.shortcut.0', 'layer3.0.shortcut.1',\n",
    "    'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.conv2', 'layer3.1.bn2',\n",
    "    'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.shortcut.0', 'layer4.0.shortcut.1',\n",
    "    'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.conv2', 'layer4.1.bn2',\n",
    "    'linear'\n",
    "]\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#Load ResNet18 model with PGD-7 adversarial training\n",
    "print('==> Loading PGD-7-trained model..')\n",
    "net_pgd7 = ResNet18()\n",
    "net_pgd7 = net_pgd7.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd7 = torch.nn.DataParallel(net_pgd7)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_pgdTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd7.load_state_dict(new_state_dict)\n",
    "\n",
    "#Load ResNet18 model with PGD adversarial training\n",
    "print('==> Loading PGD-20-trained model..')\n",
    "net_pgd20 = ResNet18()\n",
    "net_pgd20 = net_pgd20.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd20 = torch.nn.DataParallel(net_pgd20)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_pgdTraining_iter20.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd20.load_state_dict(new_state_dict)\n",
    "\n",
    "# Define a function to register hooks and capture intermediate outputs\n",
    "def register_hooks(model):\n",
    "    activations = {}\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activations[name] = output\n",
    "        return hook\n",
    "    \n",
    "    for name, layer in model.named_modules():\n",
    "        layer.register_forward_hook(get_activation(name))\n",
    "    \n",
    "    return activations\n",
    "\n",
    "\n",
    "activations_pgd7 = register_hooks(net_pgd7)\n",
    "activations_pgd20 = register_hooks(net_pgd20)\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, labels, activations):\n",
    "    x = x.to(device)\n",
    "    pgd = torchattacks.PGD(net, eps=0.01, alpha=0.001, steps=40)\n",
    "    delta_x_adv = pgd(x, labels) - x\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "\n",
    "    net.eval()\n",
    "    \n",
    "\n",
    "    activations.clear()\n",
    "    \n",
    "\n",
    "    _ = net(x)\n",
    "    output_x_layers = activations.copy()\n",
    "    \n",
    " \n",
    "    activations.clear()\n",
    "    \n",
    "    # Forward pass for perturbed input\n",
    "    _ = net(x + delta_x_adv)\n",
    "    output_x_adv_layers = activations.copy()\n",
    "    \n",
    "    susceptibilities = {}\n",
    "    for layer in output_x_layers.keys():\n",
    "        output_x = output_x_layers[layer]\n",
    "        output_x_adv = output_x_adv_layers[layer]\n",
    "        \n",
    "        # Calculate the susceptibility ratio for each layer\n",
    "        num = torch.norm(output_x - output_x_adv, p=2)\n",
    "        denom = torch.norm(delta_x_adv, p=2)\n",
    "        susceptibility = torch.exp(num / denom)\n",
    "        susceptibilities[layer] = susceptibility.item()\n",
    "    \n",
    "    return susceptibilities\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "# delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "# delta_x_adv = pgd_attack(net_pgd20, images, labels)\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibilities_pgd_iter20 = susceptibility_ratio(net_pgd20, images, labels, activations_pgd20)\n",
    "susceptibilities_pgd_iter7 = susceptibility_ratio(net_pgd7, images, labels, activations_pgd7)\n",
    "\n",
    "# Print the susceptibility ratios in a table format\n",
    "print(\"Susceptibility Ratio Comparison when the perbutation is generated by iterative attacks:\")\n",
    "print(\"{:<25} {:<15} {:<15}\".format('Layer', 'PGD-7 Model', 'PGD-20 Model'))\n",
    "for layer in layers_to_capture:\n",
    "    sus_pgd7 = susceptibilities_pgd_iter7[layer]\n",
    "    sus_pgd20 = susceptibilities_pgd_iter20[layer]\n",
    "    print(\"{:<25} {:<15.6f} {:<15.6f}\".format(layer, sus_pgd7, sus_pgd20))\n",
    "\n",
    "\n",
    "\n",
    "# for layer, sus in susceptibilities_basic.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n",
    "    \n",
    "# print(f'\\n\\n')\n",
    "    \n",
    "# for layer, sus in susceptibilities_fgsm.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n",
    "\n",
    "# print(f'\\n\\n')\n",
    "\n",
    "# for layer, sus in susceptibilities_pgd.items():\n",
    "#     print(f'Susceptibility Ratio for Layer {layer}: {sus}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m inputs, targets \u001b[38;5;241m=\u001b[39m dataiter\u001b[38;5;241m.\u001b[39mnext()\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 65\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mChaosRegularizedLoss.forward\u001b[0;34m(self, model, inputs, targets)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, targets):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Standard task-specific loss\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     task_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_entropy_loss(outputs, targets)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Chaos regularization term\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/pratyushg/resnet.py:95\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 95\u001b[0m     out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     96\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(out)\n\u001b[1;32m     97\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:423\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:419\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    417\u001b[0m                     weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    418\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ChaosRegularizedLoss(nn.Module):\n",
    "    def __init__(self, lambda_chaos=0.1, perturbation_magnitude=1e-2):\n",
    "        super(ChaosRegularizedLoss, self).__init__()\n",
    "        self.lambda_chaos = lambda_chaos\n",
    "        self.perturbation_magnitude = perturbation_magnitude\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        # Standard task-specific loss\n",
    "        outputs = model(inputs)\n",
    "        task_loss = self.cross_entropy_loss(outputs, targets)\n",
    "\n",
    "        # Chaos regularization term\n",
    "        perturbation = self.perturbation_magnitude * torch.randn_like(inputs)\n",
    "        perturbed_inputs = inputs + perturbation\n",
    "        outputs_perturbed = model(perturbed_inputs)\n",
    "\n",
    "        hidden_states = model.get_hidden_states(inputs)\n",
    "        hidden_states_perturbed = model.get_hidden_states(perturbed_inputs)\n",
    "        \n",
    "        chaos_loss = torch.mean((hidden_states - hidden_states_perturbed).pow(2))\n",
    "\n",
    "        # Combined loss\n",
    "        total_loss = task_loss + self.lambda_chaos * chaos_loss\n",
    "        return total_loss\n",
    "\n",
    "# Example usage\n",
    "# Load ResNet18 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net.load_state_dict(new_state_dict)\n",
    "\n",
    "model = net\n",
    "criterion = ChaosRegularizedLoss(lambda_chaos=0.1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "inputs, targets = dataiter.next()\n",
    "optimizer.zero_grad()\n",
    "loss = criterion(model, inputs, targets)\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1, Batch 100] loss: 1.842\n",
      "[Epoch 1, Batch 200] loss: 1.584\n",
      "[Epoch 1, Batch 300] loss: 1.465\n",
      "[Epoch 2, Batch 100] loss: 1.320\n",
      "[Epoch 2, Batch 200] loss: 1.254\n",
      "[Epoch 2, Batch 300] loss: 1.203\n",
      "[Epoch 3, Batch 100] loss: 1.122\n",
      "[Epoch 3, Batch 200] loss: 1.127\n",
      "[Epoch 3, Batch 300] loss: 1.109\n",
      "[Epoch 4, Batch 100] loss: 1.043\n",
      "[Epoch 4, Batch 200] loss: 1.069\n",
      "[Epoch 4, Batch 300] loss: 1.043\n",
      "[Epoch 5, Batch 100] loss: 1.072\n",
      "[Epoch 5, Batch 200] loss: 1.039\n",
      "[Epoch 5, Batch 300] loss: 1.084\n",
      "[Epoch 6, Batch 100] loss: 1.103\n",
      "[Epoch 6, Batch 200] loss: 1.098\n",
      "[Epoch 6, Batch 300] loss: 1.124\n",
      "[Epoch 7, Batch 100] loss: 1.111\n",
      "[Epoch 7, Batch 200] loss: 1.174\n",
      "[Epoch 7, Batch 300] loss: 1.215\n",
      "[Epoch 8, Batch 100] loss: 1.201\n",
      "[Epoch 8, Batch 200] loss: 1.284\n",
      "[Epoch 8, Batch 300] loss: 1.309\n",
      "[Epoch 9, Batch 100] loss: 1.316\n",
      "[Epoch 9, Batch 200] loss: 1.511\n",
      "[Epoch 9, Batch 300] loss: 1.398\n",
      "[Epoch 10, Batch 100] loss: 1.458\n",
      "[Epoch 10, Batch 200] loss: 1.493\n",
      "[Epoch 10, Batch 300] loss: 1.698\n",
      "[Epoch 11, Batch 100] loss: 1.703\n",
      "[Epoch 11, Batch 200] loss: 1.635\n",
      "[Epoch 11, Batch 300] loss: 2.119\n",
      "[Epoch 12, Batch 100] loss: 1.976\n",
      "[Epoch 12, Batch 200] loss: 2.263\n",
      "[Epoch 12, Batch 300] loss: 2.083\n",
      "[Epoch 13, Batch 100] loss: 2.484\n",
      "[Epoch 13, Batch 200] loss: 2.373\n",
      "[Epoch 13, Batch 300] loss: 2.537\n",
      "[Epoch 14, Batch 100] loss: 2.850\n",
      "[Epoch 14, Batch 200] loss: 2.169\n",
      "[Epoch 14, Batch 300] loss: 2.569\n",
      "[Epoch 15, Batch 100] loss: 2.888\n",
      "[Epoch 15, Batch 200] loss: 3.522\n",
      "[Epoch 15, Batch 300] loss: 2.861\n",
      "[Epoch 16, Batch 100] loss: 3.487\n",
      "[Epoch 16, Batch 200] loss: 3.397\n",
      "[Epoch 16, Batch 300] loss: 3.269\n",
      "[Epoch 17, Batch 100] loss: 3.690\n",
      "[Epoch 17, Batch 200] loss: 4.047\n",
      "[Epoch 17, Batch 300] loss: 5.685\n",
      "[Epoch 18, Batch 100] loss: 3.717\n",
      "[Epoch 18, Batch 200] loss: 4.237\n",
      "[Epoch 18, Batch 300] loss: 4.524\n",
      "[Epoch 19, Batch 100] loss: 5.173\n",
      "[Epoch 19, Batch 200] loss: 4.629\n",
      "[Epoch 19, Batch 300] loss: 6.135\n",
      "[Epoch 20, Batch 100] loss: 7.773\n",
      "[Epoch 20, Batch 200] loss: 6.356\n",
      "[Epoch 20, Batch 300] loss: 5.693\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 81.32%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Step 1: Set Up Environment and Import Libraries\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Step 2: Load CIFAR-10 Dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Step 3: Define the ResNet-18 Model\n",
    "class ResNet18WithHidden(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18WithHidden, self).__init__()\n",
    "        self.resnet18 = resnet18(pretrained=False, num_classes=10)\n",
    "        self.hidden_states = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extracting hidden states from one of the intermediate layers\n",
    "        def hook(module, input, output):\n",
    "            self.hidden_states = output\n",
    "\n",
    "        # Register hook to a layer (e.g., the layer before the last fully connected layer)\n",
    "        handle = self.resnet18.layer4[1].conv2.register_forward_hook(hook)\n",
    "        \n",
    "        output = self.resnet18(x)\n",
    "        \n",
    "        # Remove the hook after forward pass to avoid accumulating hooks\n",
    "        handle.remove()\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def get_hidden_states(self):\n",
    "        return self.hidden_states\n",
    "\n",
    "model = ResNet18WithHidden().to(device)\n",
    "\n",
    "# Step 4: Define the Custom Chaos Regularized Loss\n",
    "class ChaosRegularizedLoss(nn.Module):\n",
    "    def __init__(self, lambda_chaos=0.1, perturbation_magnitude=1e-2):\n",
    "        super(ChaosRegularizedLoss, self).__init__()\n",
    "        self.lambda_chaos = lambda_chaos\n",
    "        self.perturbation_magnitude = perturbation_magnitude\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        # Compute standard task-specific loss\n",
    "        outputs = model(inputs)\n",
    "        task_loss = self.cross_entropy_loss(outputs, targets)\n",
    "\n",
    "        # Generate small random perturbation for inputs\n",
    "        perturbation = self.perturbation_magnitude * torch.randn_like(inputs).to(inputs.device)\n",
    "        perturbed_inputs = inputs + perturbation\n",
    "\n",
    "        # Forward pass for perturbed inputs\n",
    "        _ = model(perturbed_inputs)\n",
    "\n",
    "        # Get hidden states for both original and perturbed inputs\n",
    "        hidden_states = model.get_hidden_states().detach()\n",
    "        _ = model(inputs)  # Forward pass again to get hidden states for original inputs\n",
    "        hidden_states_perturbed = model.get_hidden_states().detach()\n",
    "        \n",
    "        # Chaos regularization term (mean squared difference normalized by perturbation size)\n",
    "        chaos_loss = torch.mean((hidden_states - hidden_states_perturbed).pow(2) / perturbation.pow(2).mean())\n",
    "        \n",
    "        # Combined loss\n",
    "        total_loss = task_loss + self.lambda_chaos * chaos_loss\n",
    "        return total_loss\n",
    "\n",
    "criterion = ChaosRegularizedLoss(lambda_chaos=0.1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 5: Train the Model\n",
    "for epoch in range(20):  # Adjust the number of epochs as needed\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(model, inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet18_cifar10_chaos_regularized.pth')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Susceptibility Ratio: 1.2778984308242798\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the transformations for the dataset\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "# Load ResNet18 model\n",
    "net = model\n",
    "net = net.to(device)\n",
    "net.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define a function to calculate the susceptibility ratio\n",
    "def susceptibility_ratio(net, x, delta_x_adv):\n",
    "    x = x.to(device)\n",
    "    delta_x_adv = delta_x_adv.to(device)\n",
    "    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # Calculate h(θ; x_i)\n",
    "    output_x = net(x)\n",
    "    \n",
    "    # Calculate h(θ; x_i + δx_adv)\n",
    "    output_x_adv = net(x + delta_x_adv)\n",
    "    \n",
    "    # Calculate the susceptibility ratio\n",
    "    num = torch.norm(output_x - output_x_adv, p=2)\n",
    "    denom = torch.norm(delta_x_adv, p=2)\n",
    "    \n",
    "    susceptibility = torch.exp(num / denom)\n",
    "    return susceptibility.item()\n",
    "\n",
    "# Get a batch of training data\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Define a small adversarial perturbation\n",
    "epsilon = 0.01\n",
    "delta_x_adv = epsilon * torch.sign(torch.randn_like(images))\n",
    "\n",
    "# Calculate the susceptibility ratio for the batch\n",
    "susceptibility = susceptibility_ratio(net, images, delta_x_adv)\n",
    "print(f'Susceptibility Ratio: {susceptibility}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
