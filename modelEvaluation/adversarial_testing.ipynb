{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyush/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import *\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from resnet import *\n",
    "\n",
    "import pickle\n",
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "import os\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='PyTorch Cifar10 Training')\n",
    "# parser.add_argument('--ngpu', type=int, default=1, help='0 = CPU.')\n",
    "# parser.add_argument('--gpu_id', type=int, default=0,\n",
    "#                     help='device range [0,ngpu-1]')\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "ngpu = 1\n",
    "gpu_id = 1\n",
    "if ngpu == 1:\n",
    "    # make only devices indexed by #gpu_id visible\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net2 = ResNet18()\n",
    "net2 = net2.to(device)\n",
    "if device == 'cuda':\n",
    "    net2 = torch.nn.DataParallel(net2)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net2.parameters(), lr=lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n",
      "==> Loading FGSM-trained model..\n",
      "==> Loading PGD-trained model..\n",
      "==> Loading ChaosLoss Minimization model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ResNet18 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic = ResNet18()\n",
    "net_basic = net_basic.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic = torch.nn.DataParallel(net_basic)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic.load_state_dict(state_dict)\n",
    "\n",
    "#Load ResNet18 model with FGSM adversarial training\n",
    "print('==> Loading FGSM-trained model..')\n",
    "net_fgsm = ResNet18()\n",
    "net_fgsm = net_fgsm.to(device)\n",
    "if device == 'cuda':\n",
    "    net_fgsm = torch.nn.DataParallel(net_fgsm)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_fgsmTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_fgsm.load_state_dict(state_dict)\n",
    "\n",
    "#Load ResNet18 model with PGD adversarial training\n",
    "print('==> Loading PGD-trained model..')\n",
    "net_pgd = ResNet18()\n",
    "net_pgd = net_pgd.to(device)\n",
    "if device == 'cuda':\n",
    "    net_pgd = torch.nn.DataParallel(net_pgd)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_githubPGD20_epoch200_better.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_pgd.load_state_dict(state_dict)\n",
    "\n",
    "#Load ResNet18 model with Chaos Loss minimization training\n",
    "print('==> Loading ChaosLoss Minimization model..')\n",
    "net_chaosLoss = ResNet18()\n",
    "net_chaosLoss = net_chaosLoss.to(device)\n",
    "if device == 'cuda':\n",
    "    net_chaosLoss = torch.nn.DataParallel(net_chaosLoss)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/new_loss_function/resnet18_cifar10_chaos_regularized_pgd_torchattacks_lambdaChaos0.8_epoch200_lr0.01_iters20.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('resnet18.'):\n",
    "        name = k.replace('resnet18', 'module')\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_chaosLoss.load_state_dict(new_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_basic_copy1 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic_copy1 = ResNet18()\n",
    "net_basic_copy1 = net_basic_copy1.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic_copy1 = torch.nn.DataParallel(net_basic_copy1)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic_copy1.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_basic_copy2 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic_copy2 = ResNet18()\n",
    "net_basic_copy2 = net_basic_copy2.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic_copy2 = torch.nn.DataParallel(net_basic_copy2)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic_copy2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_basic_copy3 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic_copy3 = ResNet18()\n",
    "net_basic_copy3 = net_basic_copy3.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic_copy3 = torch.nn.DataParallel(net_basic_copy3)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic_copy3.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_basic_copy4 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic_copy4 = ResNet18()\n",
    "net_basic_copy4 = net_basic_copy4.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic_copy4 = torch.nn.DataParallel(net_basic_copy4)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic_copy4.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_basic_copy5 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic_copy5 = ResNet18()\n",
    "net_basic_copy5 = net_basic_copy5.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic_copy5 = torch.nn.DataParallel(net_basic_copy5)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic_copy5.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading basic ResNet model..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net_basic_copy6 model\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print('==> Loading basic ResNet model..')\n",
    "net_basic_copy6 = ResNet18()\n",
    "net_basic_copy6 = net_basic_copy6.to(device)\n",
    "if device == 'cuda':\n",
    "    net_basic_copy6 = torch.nn.DataParallel(net_basic_copy6)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "file_path = \"/home/pratyush/pratyushg/resnetTraining/resnet18_cifar10_basicTraining.pth\"\n",
    "state_dict = torch.load(file_path)\n",
    "\n",
    "# Create a new state dictionary without the 'module.' prefix\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    if k.startswith('module.'):\n",
    "        name = k[7:]  # remove 'module.' prefix\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "net_basic_copy6.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, net):\n",
    "\n",
    "    '''\n",
    "    This function evaluate net on test dataset\n",
    "    '''\n",
    "\n",
    "    global acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = 100 * correct / total\n",
    "    return test_loss/len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_basic on default dataset accuracy: 89 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyush/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "epochs=1\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    # train_losses.append(train(epoch, net))\n",
    "    test_losses.append(test(epoch, net_basic))\n",
    "    scheduler.step()\n",
    "    \n",
    "print('net_basic on default dataset accuracy: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "epochs=1\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    # train_losses.append(train(epoch, net))\n",
    "    test_losses.append(test(epoch, net_chaosLoss))\n",
    "    scheduler.step()\n",
    "    \n",
    "print('net_chaos100 on default dataset accuracy: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net_pgd on default dataset accuracy: 58 %\n"
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "test_losses=[]\n",
    "epochs=1\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    # train_losses.append(train(epoch, net))\n",
    "    test_losses.append(test(epoch, net_pgd))\n",
    "    scheduler.step()\n",
    "    \n",
    "print('net_pgd on default dataset accuracy: %d %%' % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FGSM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGSM(net, x, y, eps):\n",
    "        '''\n",
    "        inputs:\n",
    "            net: the network through which we pass the inputs\n",
    "            x: the original example which we aim to perturb to make an adversarial example\n",
    "            y: the true label of x\n",
    "            eps: perturbation budget\n",
    "\n",
    "        outputs:\n",
    "            x_adv : the adversarial example constructed from x\n",
    "            h_adv: output of the last softmax layer when applying net on x_adv \n",
    "            y_adv: predicted label for x_adv\n",
    "            pert: perturbation applied to x (x_adv - x)\n",
    "        '''\n",
    "\n",
    "        x_ = Variable(x.data, requires_grad=True)\n",
    "        h_ = net(x_)\n",
    "        criterion= torch.nn.CrossEntropyLoss()\n",
    "        cost = criterion(h_, y)\n",
    "        net.zero_grad()\n",
    "        cost.backward()\n",
    "\n",
    "        #perturbation\n",
    "        pert= eps*x_.grad.detach().sign()\n",
    "        \n",
    "        x_adv = x_ + pert\n",
    "\n",
    "        h_adv = net(x_adv)\n",
    "        _,y_adv=torch.max(h_adv.data,1)\n",
    "        return x_adv, h_adv, y_adv, pert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fgsm(net, net_adv, eps):\n",
    "    accuracy=0\n",
    "    net.train()\n",
    "    net_adv.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        x_adv, h_adv, y_adv, pert = FGSM (net, inputs, targets, eps)\n",
    "            \n",
    "        outputs = net_adv(x_adv)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy=test_fgsm(net_basic_copy1, net_basic, 8/255)\n",
    "# print(\"accuracy of net_basic on FGSM-attacked dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy=test_fgsm(net_basic_copy2, net_fgsm, 8/255)\n",
    "# print(\"accuracy of net_fgsm on FGSM-attacked dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of net_chaosLoss on FGSM-attacked dataset: 86.82\n"
     ]
    }
   ],
   "source": [
    "accuracy=test_fgsm(net_basic_copy3, net_chaosLoss, 8/255)\n",
    "print(\"accuracy of net_chaosLoss on FGSM-attacked dataset:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGD Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PGD(net,x,y,alpha,epsilon,iter):\n",
    "#     '''\n",
    "#     inputs:\n",
    "#         net: the network through which we pass the inputs\n",
    "#         x: the original example which we aim to perturb to make an adversarial example\n",
    "#         y: the true label of x\n",
    "#         alpha: step size\n",
    "#         epsilon: perturbation budget \n",
    "#         iter: number of iterations in the PGD algorithm\n",
    "\n",
    "#     outputs:\n",
    "#         x_adv : the adversarial example constructed from x\n",
    "#         h_adv: output of the last softmax layer when applying net on x_adv \n",
    "#         y_adv: predicted label for x_adv\n",
    "#         pert: perturbation applied to x (x_adv - x)\n",
    "#     '''\n",
    "\n",
    "#     delta = torch.zeros_like(x, requires_grad=True)\n",
    "#     for i in range(iter):\n",
    "#         criterion=nn.CrossEntropyLoss()\n",
    "#         loss = criterion(net(x + delta), y)\n",
    "#         loss.backward()\n",
    "#         delta.data = (delta + x.shape[0]*alpha*delta.grad.data).clamp(-epsilon,epsilon)\n",
    "#         delta.grad.zero_()\n",
    "#     pert = delta.detach()\n",
    "#     x_adv = x + pert\n",
    "#     h_adv = net(x_adv)\n",
    "#     _,y_adv = torch.max(h_adv.data,1)\n",
    "#     return x_adv, h_adv, y_adv, pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_PGD(net,net_pgd,alpha,eps,iter):\n",
    "#     acc=0\n",
    "#     net.train()\n",
    "#     net_pgd.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             x_adv,_,_,_=PGD(net,inputs,targets,alpha,eps,iter)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = net_pgd(x_adv)\n",
    "#                 loss = criterion(outputs, targets)\n",
    "\n",
    "#                 test_loss += loss.item()\n",
    "#                 _, predicted = outputs.max(1)\n",
    "#                 total += targets.size(0)\n",
    "#                 correct += predicted.eq(targets).sum().item()\n",
    "#     acc = 100 * correct / total\n",
    "#     return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of net_basic against PGD attack with iters= 3 :  83.12\n",
      "accuracy of net_basic against PGD attack with iters= 7 :  78.6\n",
      "accuracy of net_basic against PGD attack with iters= 12 :  75.09\n"
     ]
    }
   ],
   "source": [
    "# alpha=3/255\n",
    "# eps=8/255\n",
    "# acc1_pgd=[]\n",
    "# for iter in [3,7,12]:\n",
    "#     acc=test_PGD(net_basic_copy1,net_basic,alpha,eps,iter)\n",
    "#     print(\"accuracy of net_basic against PGD attack with iters=\",iter,\": \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of net_fgsm against PGD attack with iters= 3 :  88.64\n",
      "accuracy of net_fgsm against PGD attack with iters= 7 :  88.36\n",
      "accuracy of net_fgsm against PGD attack with iters= 12 :  88.23\n"
     ]
    }
   ],
   "source": [
    "# alpha=3/255\n",
    "# eps=8/255\n",
    "# acc1_pgd=[]\n",
    "# for iter in [3,7,12]:\n",
    "#     acc=test_PGD(net_basic_copy2,net_fgsm,alpha,eps,iter)\n",
    "#     print(\"accuracy of net_fgsm against PGD attack with iters=\",iter,\": \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha=3/255\n",
    "# eps=8/255\n",
    "# acc1_pgd=[]\n",
    "# for iter in [3,7,12]:\n",
    "#     acc=test_PGD(net_basic_copy2,net_pgd,alpha,eps,iter)\n",
    "#     print(\"accuracy of net_pgd against PGD attack with iters=\",iter,\": \",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGD Testing new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     15\u001b[0m learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[1;32m     16\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0314\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "# from numpy import copy\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# import os\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# epsilon = 0.0314\n",
    "# k = 7\n",
    "# alpha = 0.00784\n",
    "# file_name = 'pgd_adversarial_training'\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "# class LinfPGDAttack(object):\n",
    "#     def __init__(self, model):\n",
    "#         self.model = model\n",
    "\n",
    "#     def perturb(self, x_natural, y):\n",
    "#         x = x_natural.detach()\n",
    "#         x = x + torch.zeros_like(x).uniform_(-epsilon, epsilon)\n",
    "#         for i in range(k):\n",
    "#             x.requires_grad_()\n",
    "#             with torch.enable_grad():\n",
    "#                 logits = self.model(x)\n",
    "#                 loss = F.cross_entropy(logits, y)\n",
    "#             grad = torch.autograd.grad(loss, [x])[0]\n",
    "#             x = x.detach() + alpha * torch.sign(grad.detach())\n",
    "#             x = torch.min(torch.max(x, x_natural - epsilon), x_natural + epsilon)\n",
    "#             x = torch.clamp(x, 0, 1)\n",
    "#         return x\n",
    "\n",
    "# def attack(x, y, model, adversary):\n",
    "#     model_copied = copy.deepcopy(model)\n",
    "#     model_copied.eval()\n",
    "#     adversary.model = model_copied\n",
    "#     adv = adversary.perturb(x, y)\n",
    "#     return adv\n",
    "\n",
    "# net = net_basic\n",
    "\n",
    "# adversary = LinfPGDAttack(net)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "# def train(epoch):\n",
    "#     print('\\n[ Train epoch: %d ]' % epoch)\n",
    "#     net.train()\n",
    "#     train_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         adv = adversary.perturb(inputs, targets)\n",
    "#         adv_outputs = net(adv)\n",
    "#         loss = criterion(adv_outputs, targets)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "#         _, predicted = adv_outputs.max(1)\n",
    "\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('\\nCurrent batch:', str(batch_idx))\n",
    "#             print('Current adversarial train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#             print('Current adversarial train loss:', loss.item())\n",
    "\n",
    "#     print('\\nTotal adversarial train accuarcy:', 100. * correct / total)\n",
    "#     print('Total adversarial train loss:', train_loss)\n",
    "\n",
    "# def test(epoch):\n",
    "#     print('\\n[ Test epoch: %d ]' % epoch)\n",
    "#     net.eval()\n",
    "#     benign_loss = 0\n",
    "#     adv_loss = 0\n",
    "#     benign_correct = 0\n",
    "#     adv_correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             total += targets.size(0)\n",
    "\n",
    "#             outputs = net(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             benign_loss += loss.item()\n",
    "\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             benign_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print('\\nCurrent batch:', str(batch_idx))\n",
    "#                 print('Current benign test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#                 print('Current benign test loss:', loss.item())\n",
    "\n",
    "#             adv = adversary.perturb(inputs, targets)\n",
    "#             adv_outputs = net(adv)\n",
    "#             loss = criterion(adv_outputs, targets)\n",
    "#             adv_loss += loss.item()\n",
    "\n",
    "#             _, predicted = adv_outputs.max(1)\n",
    "#             adv_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print('Current adversarial test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#                 print('Current adversarial test loss:', loss.item())\n",
    "\n",
    "#     print('\\nTotal benign test accuarcy:', 100. * benign_correct / total)\n",
    "#     print('Total adversarial test Accuarcy:', 100. * adv_correct / total)\n",
    "#     print('Total benign test loss:', benign_loss)\n",
    "#     print('Total adversarial test loss:', adv_loss)\n",
    "\n",
    "#     state = {\n",
    "#         'net': net.state_dict()\n",
    "#     }\n",
    "#     if not os.path.isdir('checkpoint'):\n",
    "#         os.mkdir('checkpoint')\n",
    "#     torch.save(state, './checkpoint/' + file_name)\n",
    "#     print('Model Saved!')\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch):\n",
    "#     lr = learning_rate\n",
    "#     if epoch >= 100:\n",
    "#         lr /= 10\n",
    "#     if epoch >= 150:\n",
    "#         lr /= 10\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "# print('net_basic attacked with PGD attack: ')\n",
    "# for epoch in range(0, 1):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     # train(epoch)\n",
    "#     test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import copy\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# epsilon = 0.0314\n",
    "# k = 7\n",
    "# alpha = 0.00784\n",
    "# file_name = 'pgd_adversarial_training'\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "# class LinfPGDAttack(object):\n",
    "#     def __init__(self, model):\n",
    "#         self.model = model\n",
    "\n",
    "#     def perturb(self, x_natural, y):\n",
    "#         x = x_natural.detach()\n",
    "#         x = x + torch.zeros_like(x).uniform_(-epsilon, epsilon)\n",
    "#         for i in range(k):\n",
    "#             x.requires_grad_()\n",
    "#             with torch.enable_grad():\n",
    "#                 logits = self.model(x)\n",
    "#                 loss = F.cross_entropy(logits, y)\n",
    "#             grad = torch.autograd.grad(loss, [x])[0]\n",
    "#             x = x.detach() + alpha * torch.sign(grad.detach())\n",
    "#             x = torch.min(torch.max(x, x_natural - epsilon), x_natural + epsilon)\n",
    "#             x = torch.clamp(x, 0, 1)\n",
    "#         return x\n",
    "\n",
    "# def attack(x, y, model, adversary):\n",
    "#     model_copied = copy.deepcopy(model)\n",
    "#     model_copied.eval()\n",
    "#     adversary.model = model_copied\n",
    "#     adv = adversary.perturb(x, y)\n",
    "#     return adv\n",
    "\n",
    "# net = net_fgsm\n",
    "\n",
    "# adversary = LinfPGDAttack(net)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "# def train(epoch):\n",
    "#     print('\\n[ Train epoch: %d ]' % epoch)\n",
    "#     net.train()\n",
    "#     train_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         adv = adversary.perturb(inputs, targets)\n",
    "#         adv_outputs = net(adv)\n",
    "#         loss = criterion(adv_outputs, targets)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "#         _, predicted = adv_outputs.max(1)\n",
    "\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('\\nCurrent batch:', str(batch_idx))\n",
    "#             print('Current adversarial train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#             print('Current adversarial train loss:', loss.item())\n",
    "\n",
    "#     print('\\nTotal adversarial train accuarcy:', 100. * correct / total)\n",
    "#     print('Total adversarial train loss:', train_loss)\n",
    "\n",
    "# def test(epoch):\n",
    "#     print('\\n[ Test epoch: %d ]' % epoch)\n",
    "#     net.eval()\n",
    "#     benign_loss = 0\n",
    "#     adv_loss = 0\n",
    "#     benign_correct = 0\n",
    "#     adv_correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             total += targets.size(0)\n",
    "\n",
    "#             outputs = net(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             benign_loss += loss.item()\n",
    "\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             benign_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print('\\nCurrent batch:', str(batch_idx))\n",
    "#                 print('Current benign test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#                 print('Current benign test loss:', loss.item())\n",
    "\n",
    "#             adv = adversary.perturb(inputs, targets)\n",
    "#             adv_outputs = net(adv)\n",
    "#             loss = criterion(adv_outputs, targets)\n",
    "#             adv_loss += loss.item()\n",
    "\n",
    "#             _, predicted = adv_outputs.max(1)\n",
    "#             adv_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print('Current adversarial test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#                 print('Current adversarial test loss:', loss.item())\n",
    "\n",
    "#     print('\\nTotal benign test accuarcy:', 100. * benign_correct / total)\n",
    "#     print('Total adversarial test Accuarcy:', 100. * adv_correct / total)\n",
    "#     print('Total benign test loss:', benign_loss)\n",
    "#     print('Total adversarial test loss:', adv_loss)\n",
    "\n",
    "#     state = {\n",
    "#         'net': net.state_dict()\n",
    "#     }\n",
    "#     if not os.path.isdir('checkpoint'):\n",
    "#         os.mkdir('checkpoint')\n",
    "#     torch.save(state, './checkpoint/' + file_name)\n",
    "#     print('Model Saved!')\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch):\n",
    "#     lr = learning_rate\n",
    "#     if epoch >= 100:\n",
    "#         lr /= 10\n",
    "#     if epoch >= 150:\n",
    "#         lr /= 10\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "# print('net_fgsm attacked with PGD attack: ')\n",
    "# for epoch in range(0, 1):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     # train(epoch)\n",
    "#     test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import copy\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# import torch.backends.cudnn as cudnn\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# import os\n",
    "\n",
    "# learning_rate = 0.1\n",
    "# epsilon = 0.0314\n",
    "# k = 7\n",
    "# alpha = 0.00784\n",
    "# file_name = 'pgd_adversarial_training'\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)\n",
    "\n",
    "# class LinfPGDAttack(object):\n",
    "#     def __init__(self, model):\n",
    "#         self.model = model\n",
    "\n",
    "#     def perturb(self, x_natural, y):\n",
    "#         x = x_natural.detach()\n",
    "#         x = x + torch.zeros_like(x).uniform_(-epsilon, epsilon)\n",
    "#         for i in range(k):\n",
    "#             x.requires_grad_()\n",
    "#             with torch.enable_grad():\n",
    "#                 logits = self.model(x)\n",
    "#                 loss = F.cross_entropy(logits, y)\n",
    "#             grad = torch.autograd.grad(loss, [x])[0]\n",
    "#             x = x.detach() + alpha * torch.sign(grad.detach())\n",
    "#             x = torch.min(torch.max(x, x_natural - epsilon), x_natural + epsilon)\n",
    "#             x = torch.clamp(x, 0, 1)\n",
    "#         return x\n",
    "\n",
    "# def attack(x, y, model, adversary):\n",
    "#     model_copied = copy.deepcopy(model)\n",
    "#     model_copied.eval()\n",
    "#     adversary.model = model_copied\n",
    "#     adv = adversary.perturb(x, y)\n",
    "#     return adv\n",
    "\n",
    "# net = net_pgd\n",
    "\n",
    "# adversary = LinfPGDAttack(net)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "# def train(epoch):\n",
    "#     print('\\n[ Train epoch: %d ]' % epoch)\n",
    "#     net.train()\n",
    "#     train_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         adv = adversary.perturb(inputs, targets)\n",
    "#         adv_outputs = net(adv)\n",
    "#         loss = criterion(adv_outputs, targets)\n",
    "#         loss.backward()\n",
    "\n",
    "#         optimizer.step()\n",
    "#         train_loss += loss.item()\n",
    "#         _, predicted = adv_outputs.max(1)\n",
    "\n",
    "#         total += targets.size(0)\n",
    "#         correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "#         if batch_idx % 10 == 0:\n",
    "#             print('\\nCurrent batch:', str(batch_idx))\n",
    "#             print('Current adversarial train accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#             print('Current adversarial train loss:', loss.item())\n",
    "\n",
    "#     print('\\nTotal adversarial train accuarcy:', 100. * correct / total)\n",
    "#     print('Total adversarial train loss:', train_loss)\n",
    "\n",
    "# def test(epoch):\n",
    "#     print('\\n[ Test epoch: %d ]' % epoch)\n",
    "#     net.eval()\n",
    "#     benign_loss = 0\n",
    "#     adv_loss = 0\n",
    "#     benign_correct = 0\n",
    "#     adv_correct = 0\n",
    "#     total = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "#             inputs, targets = inputs.to(device), targets.to(device)\n",
    "#             total += targets.size(0)\n",
    "\n",
    "#             outputs = net(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             benign_loss += loss.item()\n",
    "\n",
    "#             _, predicted = outputs.max(1)\n",
    "#             benign_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print('\\nCurrent batch:', str(batch_idx))\n",
    "#                 print('Current benign test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#                 print('Current benign test loss:', loss.item())\n",
    "\n",
    "#             adv = adversary.perturb(inputs, targets)\n",
    "#             adv_outputs = net(adv)\n",
    "#             loss = criterion(adv_outputs, targets)\n",
    "#             adv_loss += loss.item()\n",
    "\n",
    "#             _, predicted = adv_outputs.max(1)\n",
    "#             adv_correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "#             if batch_idx % 10 == 0:\n",
    "#                 print('Current adversarial test accuracy:', str(predicted.eq(targets).sum().item() / targets.size(0)))\n",
    "#                 print('Current adversarial test loss:', loss.item())\n",
    "\n",
    "#     print('\\nTotal benign test accuarcy:', 100. * benign_correct / total)\n",
    "#     print('Total adversarial test Accuarcy:', 100. * adv_correct / total)\n",
    "#     print('Total benign test loss:', benign_loss)\n",
    "#     print('Total adversarial test loss:', adv_loss)\n",
    "\n",
    "#     state = {\n",
    "#         'net': net.state_dict()\n",
    "#     }\n",
    "#     if not os.path.isdir('checkpoint'):\n",
    "#         os.mkdir('checkpoint')\n",
    "#     torch.save(state, './checkpoint/' + file_name)\n",
    "#     print('Model Saved!')\n",
    "\n",
    "# def adjust_learning_rate(optimizer, epoch):\n",
    "#     lr = learning_rate\n",
    "#     if epoch >= 100:\n",
    "#         lr /= 10\n",
    "#     if epoch >= 150:\n",
    "#         lr /= 10\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "# print('net_pgd attacked with PGD attack: ')\n",
    "# for epoch in range(0, 1):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "#     # train(epoch)\n",
    "#     test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyush/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the model on adversarial examples: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchattacks\n",
    "\n",
    "# # Define the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the pretrained ResNet18 model\n",
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# model = model.to(device)\n",
    "# model.eval()\n",
    "\n",
    "# # Define the CIFAR-10 transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Load the CIFAR-10 test dataset\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Define the PGD attack\n",
    "# epsilon = 8/255  # Perturbation\n",
    "# alpha = 2/255    # Step size\n",
    "# steps = 12        # Number of iterations\n",
    "\n",
    "# pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
    "\n",
    "# # Function to test the model on adversarial examples\n",
    "# def test_model_on_adversarial(loader, model, attack):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     model.eval()\n",
    "    \n",
    "#     for data in loader:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Generate adversarial examples\n",
    "#         adv_images = attack(images, labels)\n",
    "\n",
    "#         # Forward pass the adversarial examples through the model\n",
    "#         outputs = model(adv_images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# # Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "# test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchattacks\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "model = net_chaosLoss\n",
    "model.eval()\n",
    "\n",
    "# Define the CIFAR-10 transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the PGD attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "alpha = 2/255    # Step size\n",
    "steps = 20        # Number of iterations\n",
    "\n",
    "pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
    "\n",
    "# Function to test the model on adversarial examples\n",
    "def test_model_on_adversarial(loader, model, attack):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(images, labels)\n",
    "\n",
    "        # Forward pass the adversarial examples through the model\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchattacks\n",
    "\n",
    "# # Define the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the pretrained ResNet18 model\n",
    "# model = net_basic\n",
    "# model.eval()\n",
    "\n",
    "# # Define the CIFAR-10 transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Load the CIFAR-10 test dataset\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Define the PGD attack\n",
    "# epsilon = 60/255  # Perturbation\n",
    "# alpha = 2/255    # Step size\n",
    "# steps = 20        # Number of iterations\n",
    "\n",
    "# pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps, norm='l2')\n",
    "\n",
    "# # Function to test the model on adversarial examples\n",
    "# def test_model_on_adversarial(loader, model, attack):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     model.eval()\n",
    "    \n",
    "#     for data in loader:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Generate adversarial examples\n",
    "#         adv_images = attack(images, labels)\n",
    "\n",
    "#         # Forward pass the adversarial examples through the model\n",
    "#         outputs = model(adv_images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# # Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "# test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the model on adversarial examples: 48.79%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchattacks\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "model = net_chaosLoss\n",
    "model.eval()\n",
    "\n",
    "# Define the CIFAR-10 transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the FGSM attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "\n",
    "fgsm = torchattacks.FGSM(model, eps=epsilon)\n",
    "\n",
    "# Function to test the model on adversarial examples\n",
    "def test_model_on_adversarial(loader, model, attack):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(images, labels)\n",
    "\n",
    "        # Forward pass the adversarial examples through the model\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "test_model_on_adversarial(testloader, model, fgsm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchattacks\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "model = net_fgsm\n",
    "model.eval()\n",
    "\n",
    "# Define the CIFAR-10 transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the FGSM attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "\n",
    "fgsm = torchattacks.FGSM(model, eps=epsilon)\n",
    "\n",
    "# Function to test the model on adversarial examples\n",
    "def test_model_on_adversarial(loader, model, attack):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(images, labels)\n",
    "\n",
    "        # Forward pass the adversarial examples through the model\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "test_model_on_adversarial(testloader, model, fgsm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the model on adversarial examples: 43.32%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchattacks\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "model = net_chaosLoss\n",
    "model.eval()\n",
    "\n",
    "# Define the CIFAR-10 transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the FGSM attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "\n",
    "fgsm = torchattacks.FGSM(model, eps=epsilon)\n",
    "\n",
    "# Function to test the model on adversarial examples\n",
    "def test_model_on_adversarial(loader, model, attack):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(images, labels)\n",
    "\n",
    "        # Forward pass the adversarial examples through the model\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "test_model_on_adversarial(testloader, model, fgsm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchattacks\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "model = net_fgsm\n",
    "model.eval()\n",
    "\n",
    "# Define the CIFAR-10 transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the PGD attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "alpha = 2/255    # Step size\n",
    "steps = 20        # Number of iterations\n",
    "\n",
    "pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
    "\n",
    "# Function to test the model on adversarial examples\n",
    "def test_model_on_adversarial(loader, model, attack):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(images, labels)\n",
    "\n",
    "        # Forward pass the adversarial examples through the model\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchattacks\n",
    "\n",
    "# # Define the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the pretrained ResNet18 model\n",
    "# model = net_fgsm\n",
    "# model.eval()\n",
    "\n",
    "# # Define the CIFAR-10 transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Load the CIFAR-10 test dataset\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Define the PGD attack\n",
    "# epsilon = 60/255  # Perturbation\n",
    "# alpha = 2/255    # Step size\n",
    "# steps = 20        # Number of iterations\n",
    "\n",
    "# pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps, norm='l2')\n",
    "\n",
    "# # Function to test the model on adversarial examples\n",
    "# def test_model_on_adversarial(loader, model, attack):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     model.eval()\n",
    "    \n",
    "#     for data in loader:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Generate adversarial examples\n",
    "#         adv_images = attack(images, labels)\n",
    "\n",
    "#         # Forward pass the adversarial examples through the model\n",
    "#         outputs = model(adv_images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# # Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "# test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import torchattacks\n",
    "\n",
    "# # Define the device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load the pretrained ResNet18 model\n",
    "# model = net_pgd\n",
    "# model.eval()\n",
    "\n",
    "# # Define the CIFAR-10 transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Load the CIFAR-10 test dataset\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Define the PGD attack\n",
    "# epsilon = 60/255  # Perturbation\n",
    "# alpha = 2/255    # Step size\n",
    "# steps = 20        # Number of iterations\n",
    "\n",
    "# pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps, norm='l2')\n",
    "\n",
    "# # Function to test the model on adversarial examples\n",
    "# def test_model_on_adversarial(loader, model, attack):\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     model.eval()\n",
    "    \n",
    "#     for data in loader:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "#         # Generate adversarial examples\n",
    "#         adv_images = attack(images, labels)\n",
    "\n",
    "#         # Forward pass the adversarial examples through the model\n",
    "#         outputs = model(adv_images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# # Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "# test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Accuracy of the model on adversarial examples: 52.85%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchattacks\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pretrained ResNet18 model\n",
    "model = net_pgd\n",
    "model.eval()\n",
    "\n",
    "# Define the CIFAR-10 transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 test dataset\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the PGD attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "alpha = 2/255    # Step size\n",
    "steps = 20        # Number of iterations\n",
    "\n",
    "pgd = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
    "\n",
    "# Function to test the model on adversarial examples\n",
    "def test_model_on_adversarial(loader, model, attack):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for data in loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial examples\n",
    "        adv_images = attack(images, labels)\n",
    "\n",
    "        # Forward pass the adversarial examples through the model\n",
    "        outputs = model(adv_images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * correct / total:.2f}%')\n",
    "\n",
    "# Test the model on the adversarially-attacked CIFAR-10 test set\n",
    "test_model_on_adversarial(testloader, model, pgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
