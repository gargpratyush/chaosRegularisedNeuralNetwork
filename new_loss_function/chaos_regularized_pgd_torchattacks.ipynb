{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import argparse\n",
    "import os\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='PyTorch Cifar10 Training')\n",
    "# parser.add_argument('--ngpu', type=int, default=1, help='0 = CPU.')\n",
    "# parser.add_argument('--gpu_id', type=int, default=0,\n",
    "#                     help='device range [0,ngpu-1]')\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "ngpu = 1\n",
    "gpu_id = 1\n",
    "if ngpu == 1:\n",
    "    # make only devices indexed by #gpu_id visible\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1, Batch 100] loss: 2.436\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "# import torch.backends.cudnn as cudnn\n",
    "# from torchvision.models import resnet18\n",
    "# import torchattacks\n",
    "# from resnet import *\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import time\n",
    "\n",
    "# start_time = time.time()\n",
    "\n",
    "# # Your code here\n",
    "\n",
    "\n",
    "\n",
    "# # Set up device\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Load ResNet18 from file\n",
    "# net = ResNet18()\n",
    "# net = net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "\n",
    "# # Load CIFAR-10 dataset\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "# ])\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# # Define the ResNet-18 Model\n",
    "# class ResNet18WithOutput(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ResNet18WithOutput, self).__init__()\n",
    "#         self.resnet18 = net\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         output = self.resnet18(x)\n",
    "#         return output\n",
    "\n",
    "# model = ResNet18WithOutput().to(device)\n",
    "\n",
    "# # Custom Chaos Regularized Loss with Adversarial Perturbations using torchattacks.PGD\n",
    "# class ChaosRegularizedLoss(nn.Module):\n",
    "#     def __init__(self, model, lambda_chaos=2.0, eps=8/255, alpha=2/255, iters=10):\n",
    "#         super(ChaosRegularizedLoss, self).__init__()\n",
    "#         self.lambda_chaos = lambda_chaos\n",
    "#         self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "#         self.pgd_attack = torchattacks.PGD(model, eps=eps, alpha=alpha, steps=iters)\n",
    "\n",
    "#     def forward(self, model, inputs, targets):\n",
    "#         # Compute standard task-specific loss using cross-entropy\n",
    "#         outputs = model(inputs)\n",
    "#         task_loss = self.cross_entropy_loss(outputs, targets)\n",
    "\n",
    "#         adv_inputs = self.pgd_attack(inputs, targets)\n",
    "#         outputs_adv = model(adv_inputs)\n",
    "\n",
    "#         # Chaos regularization term (mean squared difference divided by the perturbation)\n",
    "#         perturbation = adv_inputs - inputs\n",
    "#         chaos_loss = torch.mean((outputs - outputs_adv).pow(2) / perturbation.pow(2).mean())\n",
    "\n",
    "#         # Combined loss\n",
    "#         total_loss = task_loss + self.lambda_chaos * chaos_loss\n",
    "#         return total_loss\n",
    "\n",
    "# criterion = ChaosRegularizedLoss(model, lambda_chaos=2.0, eps=8/255, alpha=3/255, iters=10)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # Train the Model\n",
    "# training_loss = []\n",
    "# for epoch in range(3): \n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for i, data in enumerate(trainloader, 0):\n",
    "#         inputs, targets = data\n",
    "#         inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         loss = criterion(model, inputs, targets)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "#         if i % 100 == 99:  # Print every 100 mini-batches\n",
    "#             training_loss.append(running_loss / 100)\n",
    "#             print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "#             running_loss = 0.0\n",
    "\n",
    "# print('Finished Training')\n",
    "\n",
    "# # Save the trained model\n",
    "# torch.save(model.state_dict(), 'resnet18_cifar10_chaos_regularized_pgd_torchattacks_lambdaChaos2.0_epoch100_lr0.01.pth')\n",
    "\n",
    "# # Evaluate the model on the test set\n",
    "# model.eval()\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# with torch.no_grad():\n",
    "#     for data in testloader:\n",
    "#         images, labels = data\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "#         outputs = model(images)\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "\n",
    "# print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n",
    "# end_time = time.time()\n",
    "# print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "\n",
    "# # Plot the training and test losses\n",
    "# epochs = range(1, len(training_loss) + 1)\n",
    "# plt.plot(epochs, training_loss, label='Training loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pratyush/miniconda3/envs/pytorch_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[Epoch 1, Batch 100] loss: 2.283\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.models import resnet18\n",
    "import torchattacks\n",
    "from resnet import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load ResNet18 from file\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the ResNet-18 Model\n",
    "class ResNet18WithOutput(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18WithOutput, self).__init__()\n",
    "        self.resnet18 = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.resnet18(x)\n",
    "        return output\n",
    "\n",
    "model = ResNet18WithOutput().to(device)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 0.01\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "# Custom Chaos Regularized Loss with Adversarial Perturbations using torchattacks.PGD\n",
    "class ChaosRegularizedLoss(nn.Module):\n",
    "    def __init__(self, model, lambda_chaos=0.8, eps=8/255, alpha=3/255, iters=10):\n",
    "        super(ChaosRegularizedLoss, self).__init__()\n",
    "        self.lambda_chaos = lambda_chaos\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.pgd_attack = torchattacks.PGD(model, eps=eps, alpha=alpha, steps=iters)\n",
    "\n",
    "    def forward(self, model, inputs, targets):\n",
    "        # Compute standard task-specific loss using cross-entropy\n",
    "        outputs = model(inputs)\n",
    "        task_loss = self.cross_entropy_loss(outputs, targets)\n",
    "\n",
    "        adv_inputs = self.pgd_attack(inputs, targets)\n",
    "        outputs_adv = model(adv_inputs)\n",
    "\n",
    "        # Chaos regularization term (mean squared difference divided by the perturbation)\n",
    "        perturbation = adv_inputs - inputs\n",
    "        chaos_loss = torch.mean((outputs - outputs_adv).pow(2) / perturbation.pow(2).mean())\n",
    "\n",
    "        # Combined loss\n",
    "        total_loss = task_loss + self.lambda_chaos * chaos_loss\n",
    "        return total_loss\n",
    "\n",
    "criterion = ChaosRegularizedLoss(model, lambda_chaos=0.8, eps=8/255, alpha=3/255, iters=10)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "criterion_benign = nn.CrossEntropyLoss()\n",
    "optimizer_benign = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "# Train the Model\n",
    "training_loss = []\n",
    "test_adv_loss_list = []\n",
    "test_benign_loss_list = []\n",
    "\n",
    "test_adv_accuracy = []\n",
    "test_benign_accuracy = []\n",
    "\n",
    "# Define the PGD attack\n",
    "epsilon = 8/255  # Perturbation\n",
    "alpha = 2/255    # Step size\n",
    "steps = 20        # Number of iterations\n",
    "\n",
    "pgdattack = torchattacks.PGD(model, eps=epsilon, alpha=alpha, steps=steps)\n",
    "\n",
    "for epoch in range(200): \n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, targets = data\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(model, inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:  # Print every 100 mini-batches\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n",
    "            # running_loss = 0.0\n",
    "        \n",
    "    training_loss.append(running_loss / 100)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Function to test the model on adversarial examples\n",
    "    adv_correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    test_adv_loss = 0.0\n",
    "    \n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        adv_images = pgdattack(images, labels) # Generate adversarial examples\n",
    "        outputs = model(adv_images) # Forward pass the adversarial examples through the model\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        adv_correct += (predicted == labels).sum().item()\n",
    "        loss = criterion(model, adv_images, labels)\n",
    "        test_adv_loss += loss.item()\n",
    "\n",
    "    test_adv_loss_list.append(test_adv_loss / len(testloader))\n",
    "    print(f'Accuracy of the model on adversarial examples: {100 * adv_correct / total:.2f}%')\n",
    "    test_adv_accuracy.append(100 * adv_correct / total)\n",
    "    \n",
    "    benign_loss = 0\n",
    "    benign_correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        benign_correct += (predicted == targets).sum().item()\n",
    "        loss = criterion(model, images, labels)\n",
    "        benign_loss += loss.item()\n",
    "        \n",
    "    test_benign_loss_list.append(benign_loss / len(testloader))\n",
    "    print(f'[Epoch {epoch + 1}] test benign loss: {benign_loss / len(testloader):.3f}')\n",
    "    test_benign_accuracy.append(100 * benign_correct / total)\n",
    "            \n",
    "    \n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'resnet18_cifar10_chaos_regularized_pgd_torchattacks_lambdaChaos0.8_epoch200_lr0.01_iters10.pth')\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and test losses\n",
    "epochs = range(1, len(training_loss) + 1)\n",
    "test_epochs = range(1, len(test_adv_loss_list) + 1)\n",
    "plt.plot(epochs, training_loss, label='Training loss')\n",
    "plt.plot(test_epochs, test_adv_loss_list, label='Test loss in adversarial examples')\n",
    "plt.plot(test_epochs, test_benign_loss_list, label='Test loss in benign examples')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the test accuracy\n",
    "plt.plot(test_epochs, test_adv_accuracy, label='Test accuracy in adversarial examples')\n",
    "plt.plot(test_epochs, test_benign_accuracy, label='Test accuracy in benign examples')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
